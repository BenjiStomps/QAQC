{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a17c3d-49be-4784-bb24-514a4d29d816",
   "metadata": {},
   "source": [
    "# Code Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759b286b-2863-44d1-8790-5dd3caf3379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantaq\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from quantaq.utils import to_dataframe\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import variation\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import probplot\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907a7c8-ae04-4b2d-9a77-940a67954bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch, start, end, resample_length=\"1min\", na_limit=0.15):\n",
    "    \"\"\"\n",
    "    `load_data` will download data from the testing chamber, report and drop units with issues connecting, and return a DataFrame. \n",
    "\n",
    "    :param batch: The name of the batch to pass to the API for downloading.\n",
    "    :type batch: string\n",
    "    :param start: The start time of the data of interest, formatted like: \"2021-05-30 09:00:00\".\n",
    "    :type start: string\n",
    "    :param end: The end time of the data of interest, formatted like: \"2021-05-30 09:00:00\".\n",
    "    :type end: string\n",
    "    :param resample_length: Interval to be used in resampling, defaults to \"1min\".\n",
    "    :type resample_length: ???\n",
    "    :param na_limit: ???\n",
    "    :type na_limit: float\n",
    "    :return: ???.\n",
    "    :rtype: ???\n",
    "    \"\"\"\n",
    "    sensor_cols = ['met.pressure', 'met.rh', 'met.temp', 'neph.bin0', 'neph.bin1', 'neph.bin2', 'neph.bin3', 'neph.bin4', 'neph.bin5', 'neph.pm1', 'neph.pm10', 'neph.pm25', 'opc.bin0', 'opc.bin1', 'opc.bin10', 'opc.bin11', 'opc.bin12', 'opc.bin13', 'opc.bin14', 'opc.bin15', 'opc.bin16', 'opc.bin17', 'opc.bin18', 'opc.bin19', 'opc.bin2', 'opc.bin20', 'opc.bin21', 'opc.bin22', 'opc.bin23', 'opc.bin3', 'opc.bin4', 'opc.bin5', 'opc.bin6', 'opc.bin7', 'opc.bin8', 'opc.bin9', 'opc.pm1', 'opc.pm10', 'opc.pm25', 'opc.rh', 'opc.temp']\n",
    "    nonsensor_cols = ['flag', 'sn', 'timestamp', 'timestamp_local', 'url', 'geo.lat', 'geo.lon']   \n",
    "    \n",
    "    if steady_start==None:\n",
    "        steady_start=start\n",
    "    if steady_end==None:\n",
    "        steady_end=end\n",
    "    \n",
    "    # Setup the API Client\n",
    "    client = quantaq.QuantAQAPIClient()\n",
    "    \n",
    "    # Retrieve the devices\n",
    "    devices = client.devices.list(team=\"Batch 3.1\")\n",
    "    \n",
    "    frames = []\n",
    "    unit_len = {}\n",
    "\n",
    "    with tqdm(total=len(devices), desc=\"API Download\") as pbar:\n",
    "        for each in devices:\n",
    "            if (np.datetime64(each['last_seen']) > np.datetime64(start)) & (np.datetime64(each['created']) < np.datetime64(end)):\n",
    "                data = client.data.list(sn=each[\"sn\"], start=start, stop=end, raw=True, per_page=500)\n",
    "                frame = to_dataframe(data)\n",
    "                unit_len[each[\"sn\"]] = len(frame)\n",
    "                if len(frame)>0:\n",
    "                    if frame.drop(nonsensor_cols, axis=1).isna().sum().sum() == 0:\n",
    "                        # Resample?\n",
    "                        frame = frame.resample(resample_length, on='timestamp').mean().reset_index()\n",
    "                        frame[\"sn\"] = each[\"sn\"]\n",
    "                        # Append\n",
    "                        frames.append(frame)\n",
    "                    else:\n",
    "                        na_frame = frame.drop(nonsensor_cols, axis=1).isna()\n",
    "                        print(f\"WARNING: Unit {each['sn']} returning unexpected missing values for {list(na_frame.columns[na_frame.sum()>0])}\")\n",
    "                else:\n",
    "                    print(f\"WARNING: Unit {each['sn']} not recording in timeframe\")\n",
    "            else:\n",
    "                print(f\"WARNING: Unit {each['sn']} not connecting in timeframe\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    frames = pd.concat(frames)\n",
    "\n",
    "    # Set the datatype for the flag\n",
    "    frames[\"flag\"] = frames[\"flag\"].astype(\"int8\", errors='ignore')\n",
    "\n",
    "    # Drop empty columns\n",
    "    frames = frames.dropna(how='all', axis=1)\n",
    "    \n",
    "    # Pick out frames that give a lot of NaNs\n",
    "#     frames_nnas = frames[[\"sn\",\"opc.bin0\"]].groupby(\"sn\").apply(lambda x: (~x.isna()).sum())[\"opc.bin0\"]\n",
    "#     highna_sn = list(frames_nnas.index[frames_nnas < (n_samples * (1 - na_limit))])\n",
    "    for key in unit_len: unit_len[key] = 100*unit_len[key]/max(unit_len.values())\n",
    "    low_data_sns = {key:val for (key,val) in unit_len.items() if val<85}\n",
    "    if len(low_data_sns) > 0:\n",
    "        for sn,missing_data_pct in low_data_sns.items():\n",
    "            print(f\"WARNING: Unit {sn} only reports {str(missing_data_pct)[:4]}% of data\")\n",
    "        frames = frames[~frames[\"sn\"].isin(list(low_data_sns.keys()))]\n",
    "    \n",
    "    # all non- or low-reporting units have been filtered out at the point\n",
    "    sns_list = list(frames[\"sn\"].unique())\n",
    "    print(f\"The number of recording units is {len(sns_list)}\")\n",
    "    \n",
    "    # Set timestamp as index\n",
    "    frames.set_index(frames[\"timestamp\"], inplace=True)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "def find window(df, var):\n",
    "    var_trend = df[[\"timestamp\", var]].groupby(\"timestamp\").quantile(q=[0.25, 0.5, 0.75])\n",
    "    fig = px.line(var_trend, x=\"timestamp\", y=var, title= f\"Median {var} over time\", render_mode=\"webgl\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ecfc2-0460-4542-b58e-b8363d799596",
   "metadata": {},
   "source": [
    "* TODO: produce Axis with trend and problem units\n",
    "* TODO: elevate ~5 best units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea433978-c840-4f78-ab22-b4c3d79d095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_units(df, var, steady_start=None, steady_end=None, threshold_factor=2):\n",
    "    \n",
    "    # build a multiindexed df with var as column, sn and timestamp as index, and restricted to the time between steady_start and steady_end\n",
    "    df_steady = df[[var,\"sn\", \"timestamp\"]].copy()\n",
    "    df_steady[\"timestamp\"] = pd.to_datetime(df_steady[\"timestamp\"])\n",
    "    df_steady.set_index([\"sn\",\"timestamp\"], inplace=True)\n",
    "    if not (steady_start==None or steady_end==None):\n",
    "        df_steady = df_steady.loc[(slice(None),slice(steady_start,steady_end)),:]\n",
    "    \n",
    "    # compute the scaling factors (neph_scale) needed so that each module will have the same mean over time (as in neph_scaled)\n",
    "    var_scale = df_steady.groupby(level=0).mean()\n",
    "    var_scale = var_scale.median()/var_scale\n",
    "    var_scaled = df_steady*var_scale\n",
    "    \n",
    "    var_scaled_trend = var_scaled.groupby(level=1).median()\n",
    "    var_std_list = (var_scaled.divide(var_scaled_trend, axis=0)).groupby(level=0).std()\n",
    "    var_std_threshold = var_std_list.median()[0]*threshold_factor\n",
    "    \n",
    "    problem_units = var_std_list[var_std_list[var] > var_std_threshold]\n",
    "    if len(problem_units)>0:\n",
    "        print(f\"Median standard deviation is {var_std_list.median()[0]}\")\n",
    "        print(f\"Modules which are inconsistent in {var}:\")\n",
    "        print(problem_units)\n",
    "        \n",
    "        return list(problem_units.index), var_std_list\n",
    "    else:\n",
    "        print(f\"No issues found with {var}.\")\n",
    "        return [], var_std_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bad1cd-dc0b-4ea1-a636-2beeec7bf303",
   "metadata": {},
   "source": [
    "* TODO: Facilitate easy further data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0ce1e8-86d8-484c-9fd6-34d231c3b30e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def qaqc_command(batch, start, end, steady_start=None, steady_end=None, resample_length=\"1min\", na_limit=0.15):\n",
    "    \n",
    "    sensor_cols = ['met.pressure', 'met.rh', 'met.temp', 'neph.bin0', 'neph.bin1', 'neph.bin2', 'neph.bin3', 'neph.bin4', 'neph.bin5', 'neph.pm1', 'neph.pm10', 'neph.pm25', 'opc.bin0', 'opc.bin1', 'opc.bin10', 'opc.bin11', 'opc.bin12', 'opc.bin13', 'opc.bin14', 'opc.bin15', 'opc.bin16', 'opc.bin17', 'opc.bin18', 'opc.bin19', 'opc.bin2', 'opc.bin20', 'opc.bin21', 'opc.bin22', 'opc.bin23', 'opc.bin3', 'opc.bin4', 'opc.bin5', 'opc.bin6', 'opc.bin7', 'opc.bin8', 'opc.bin9', 'opc.pm1', 'opc.pm10', 'opc.pm25', 'opc.rh', 'opc.temp']\n",
    "    opc_cols = ['opc.bin0', 'opc.bin1', 'opc.bin2', 'opc.bin3', 'opc.bin4', 'opc.bin5', 'opc.bin6', 'opc.bin7', 'opc.bin8', 'opc.bin9']\n",
    "    nonsensor_cols = ['flag', 'sn', 'timestamp', 'timestamp_local', 'url', 'geo.lat', 'geo.lon']   \n",
    "    \n",
    "    if steady_start==None:\n",
    "        steady_start=start\n",
    "    if steady_end==None:\n",
    "        steady_end=end\n",
    "    \n",
    "    # Setup the API Client\n",
    "    client = quantaq.QuantAQAPIClient()\n",
    "    \n",
    "    # Retrieve the devices\n",
    "    devices = client.devices.list(team=\"Batch 3.1\")\n",
    "    \n",
    "    frames = []\n",
    "    unit_len = {}\n",
    "\n",
    "    with tqdm(total=len(devices), desc=\"API Download\") as pbar:\n",
    "        for each in devices:\n",
    "            if (np.datetime64(each['last_seen']) > np.datetime64(start)) & (np.datetime64(each['created']) < np.datetime64(end)):\n",
    "                data = client.data.list(sn=each[\"sn\"], start=start, stop=end, raw=True, per_page=500)\n",
    "                frame = to_dataframe(data)\n",
    "                unit_len[each[\"sn\"]] = len(frame)\n",
    "                if len(frame)>0:\n",
    "                    if frame.drop(nonsensor_cols, axis=1).isna().sum().sum() == 0:\n",
    "                        # Resample?\n",
    "                        frame = frame.resample(resample_length, on='timestamp').mean().reset_index()\n",
    "                        frame[\"sn\"] = each[\"sn\"]\n",
    "                        # Append\n",
    "                        frames.append(frame)\n",
    "                    else:\n",
    "                        na_frame = frame.drop(nonsensor_cols, axis=1).isna()\n",
    "                        print(f\"WARNING: Unit {each['sn']} returning unexpected missing values for {list(na_frame.columns[na_frame.sum()>0])}\")\n",
    "                else:\n",
    "                    print(f\"WARNING: Unit {each['sn']} not recording in timeframe\")\n",
    "            else:\n",
    "                print(f\"WARNING: Unit {each['sn']} not connecting in timeframe\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    frames = pd.concat(frames)\n",
    "\n",
    "    # Set the datatype for the flag\n",
    "    frames[\"flag\"] = frames[\"flag\"].astype(\"int8\", errors='ignore')\n",
    "\n",
    "    # Drop empty columns\n",
    "    frames = frames.dropna(how='all', axis=1)\n",
    "    \n",
    "    # Pick out frames that give a lot of NaNs\n",
    "#     frames_nnas = frames[[\"sn\",\"opc.bin0\"]].groupby(\"sn\").apply(lambda x: (~x.isna()).sum())[\"opc.bin0\"]\n",
    "#     highna_sn = list(frames_nnas.index[frames_nnas < (n_samples * (1 - na_limit))])\n",
    "    for key in unit_len: unit_len[key] = 100*unit_len[key]/max(unit_len.values())\n",
    "    low_data_sns = {key:val for (key,val) in unit_len.items() if val<85}\n",
    "    if len(low_data_sns) > 0:\n",
    "        for sn,missing_data_pct in low_data_sns.items():\n",
    "            print(f\"WARNING: Unit {sn} only reports {str(missing_data_pct)[:4]}% of data\")\n",
    "        frames = frames[~frames[\"sn\"].isin(list(low_data_sns.keys()))]\n",
    "    \n",
    "    # all non- or low-reporting units have been filtered out at the point\n",
    "    sns_list = list(frames[\"sn\"].unique())\n",
    "    print(f\"The number of recording units is {len(sns_list)}\")\n",
    "    \n",
    "    # Set timestamp as index\n",
    "    frames.set_index(frames[\"timestamp\"], inplace=True)\n",
    "    \n",
    "    # construct multindex df with opc data for the steady state\n",
    "    opc_steady = frames[opc_cols + ['sn', \"timestamp\"]].copy()\n",
    "    opc_steady[\"timestamp\"] = pd.to_datetime(opc_steady[\"timestamp\"])\n",
    "    opc_steady = opc_steady.set_index([\"sn\", \"timestamp\"])\n",
    "    opc_steady = opc_steady.loc[(slice(None),slice(steady_start,steady_end)),:]\n",
    "\n",
    "    opc_scale = opc_steady.groupby(level=0).mean().sum(axis=1)\n",
    "    opc_scale = opc_scale.mean()/opc_scale\n",
    "    \n",
    "    print(\"opc_scale.head\")\n",
    "    print(opc_scale.head())\n",
    "    \n",
    "    # build a multiindexed df, neph_steady, with neph.bin0 as column, sn and timestamp as index, and restricted to the time between steady_start and steady_end\n",
    "    neph_steady = frames[[\"neph.bin0\",\"sn\", \"timestamp\"]].copy()\n",
    "    neph_steady[\"timestamp\"] = pd.to_datetime(neph_steady[\"timestamp\"])\n",
    "    neph_steady.set_index([\"sn\",\"timestamp\"], inplace=True)\n",
    "    neph_steady = neph_steady.loc[(slice(None),slice(steady_start,steady_end)),:]\n",
    "    \n",
    "    # compute the scaling factors (neph_scale) needed so that each module will have the same mean over time (as in neph_scaled)\n",
    "    neph_scale = neph_steady.groupby(level=0).mean()\n",
    "    neph_scale = neph_scale.median()/neph_scale\n",
    "    neph_scaled = neph_steady*neph_scale\n",
    "    \n",
    "    # compute the square of the rolling standard deviation and build a Series with each module's average std\n",
    "    neph_rstd_list = ((neph_scaled\n",
    "                       .reset_index([\"sn\"])\n",
    "                       .groupby(\"sn\", as_index=False)\n",
    "                       .rolling(pd.to_timedelta(\"5min\"), win_type='gaussian')\n",
    "                       .std()\n",
    "                       **2\n",
    "                      )\n",
    "                      .groupby(level=0)\n",
    "                      .mean()\n",
    "                     )\n",
    "    neph_rstd_threshold = neph_rstd_list.median()[0]*2\n",
    "    print(f\"rstd threshold: {neph_rstd_threshold}\")\n",
    "    print(\"Modules with a lot of noise in neph.bin0:\")\n",
    "    print(neph_rstd_list[neph_rstd_list[\"neph.bin0\"] > neph_rstd_threshold])\n",
    "    \n",
    "    neph_scaled_trend = neph_scaled.groupby(level=1).median()\n",
    "    neph_std_list = (neph_scaled.divide(neph_scaled_trend, axis=0)).groupby(level=0).std()\n",
    "    neph_std_threshold = neph_std_list.median()[0]*2\n",
    "    print(\"Modules which are inconsistent in neph.bin0:\")\n",
    "    print(neph_std_list[neph_std_list[\"neph.bin0\"] > neph_std_threshold])\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b2f4e-cf8a-43f6-96a1-cea74272e352",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209875c-720d-478a-89cc-6afbfccd2a45",
   "metadata": {},
   "source": [
    "* TODO: Flag data that seems to not be in the chamber?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d79870-5172-42d6-bf42-eaf42f0d3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(batch=\"Batch 3.1\", start=\"2021-05-30 09:00:00\", end=\"2021-05-31 10:00:00\")\n",
    "\n",
    "find_window(df,\"neph.bin0\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3c924-a2db-4a94-8ef6-867fd618c12d",
   "metadata": {},
   "source": [
    "Using the above plot, you may define an appropriate steady state window below.  Rerun for different variables as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c92cea-c770-4866-b9d8-8d079b88e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_start =\n",
    "steady_end = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881a244d-b540-4232-8b68-8b46a2b83974",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c668c746dc654689aab07700eda07d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "API Download:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Unit MOD-PM-00141 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00206 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00211 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00214 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00215 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00217 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00219 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00220 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00224 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00225 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00228 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00229 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00233 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00236 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00237 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00238 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00239 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00241 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00242 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00243 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00245 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00247 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00248 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00250 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00211 only reports 0.0% of data\n",
      "WARNING: Unit MOD-PM-00213 only reports 49.9% of data\n",
      "WARNING: Unit MOD-PM-00232 only reports 70.6% of data\n",
      "WARNING: Unit MOD-PM-00236 only reports 0.0% of data\n",
      "WARNING: Unit MOD-PM-00240 only reports 66.6% of data\n",
      "WARNING: Unit MOD-PM-00245 only reports 0.0% of data\n",
      "WARNING: Unit MOD-PM-00250 only reports 0.0% of data\n",
      "The number of recording units is 31\n",
      "opc_scale.head\n",
      "sn\n",
      "MOD-PM-00053     0.902558\n",
      "MOD-PM-00066     0.746094\n",
      "MOD-PM-00075    57.467692\n",
      "MOD-PM-00081    19.128658\n",
      "MOD-PM-00082    17.686309\n",
      "dtype: float64\n",
      "rstd threshold: 536679.0445348667\n",
      "Modules with a lot of noise in neph.bin0:\n",
      "                 neph.bin0\n",
      "sn                        \n",
      "MOD-PM-00075  1.122859e+08\n",
      "MOD-PM-00081  2.906104e+07\n",
      "MOD-PM-00082  2.375387e+07\n",
      "MOD-PM-00083  1.261647e+08\n",
      "MOD-PM-00085  6.456529e+07\n",
      "MOD-PM-00227  1.301058e+06\n",
      "MOD-PM-00235  1.697018e+06\n",
      "MOD-PM-00244  1.300832e+06\n",
      "MOD-PM-00246  1.862785e+07\n",
      "MOD-PM-00249  1.413026e+07\n",
      "Modules which are inconsistent in neph.bin0:\n",
      "              neph.bin0\n",
      "sn                     \n",
      "MOD-PM-00075   0.775496\n",
      "MOD-PM-00081   0.471507\n",
      "MOD-PM-00082   0.445035\n",
      "MOD-PM-00083   0.757659\n",
      "MOD-PM-00085   0.447959\n",
      "MOD-PM-00227   0.214566\n",
      "MOD-PM-00246   0.169934\n",
      "MOD-PM-00249   0.116688\n"
     ]
    }
   ],
   "source": [
    "qaqc_command(batch=\"Batch 3.1\", start=\"2021-05-30 09:00:00\", end=\"2021-05-31 10:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a17d98-836f-4e96-9300-a2c7757283e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebab392490204f6591108dfae04239d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "API Download:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Unit MOD-PM-00210 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00214 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00217 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00219 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00225 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00234 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00238 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00240 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00241 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00243 not recording in timeframe\n",
      "WARNING: Unit MOD-PM-00245 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00247 not connecting in timeframe\n",
      "WARNING: Unit MOD-PM-00204 only reports 68.5% of data\n",
      "WARNING: Unit MOD-PM-00206 only reports 2.23% of data\n",
      "WARNING: Unit MOD-PM-00213 only reports 34.6% of data\n",
      "WARNING: Unit MOD-PM-00215 only reports 0.39% of data\n",
      "WARNING: Unit MOD-PM-00216 only reports 46.2% of data\n",
      "WARNING: Unit MOD-PM-00218 only reports 68.1% of data\n",
      "WARNING: Unit MOD-PM-00220 only reports 0.39% of data\n",
      "WARNING: Unit MOD-PM-00222 only reports 4.95% of data\n",
      "WARNING: Unit MOD-PM-00224 only reports 3.43% of data\n",
      "WARNING: Unit MOD-PM-00226 only reports 41.4% of data\n",
      "WARNING: Unit MOD-PM-00227 only reports 18.0% of data\n",
      "WARNING: Unit MOD-PM-00228 only reports 39.2% of data\n",
      "WARNING: Unit MOD-PM-00229 only reports 17.9% of data\n",
      "WARNING: Unit MOD-PM-00230 only reports 57.9% of data\n",
      "WARNING: Unit MOD-PM-00233 only reports 40.9% of data\n",
      "WARNING: Unit MOD-PM-00237 only reports 21.0% of data\n",
      "WARNING: Unit MOD-PM-00238 only reports 0.0% of data\n",
      "WARNING: Unit MOD-PM-00239 only reports 62.2% of data\n",
      "WARNING: Unit MOD-PM-00240 only reports 0.0% of data\n",
      "WARNING: Unit MOD-PM-00242 only reports 45.9% of data\n",
      "WARNING: Unit MOD-PM-00243 only reports 0.0% of data\n",
      "WARNING: Unit MOD-PM-00248 only reports 22.9% of data\n",
      "The number of recording units is 19\n",
      "sn\n",
      "MOD-PM-00201    0.902044\n",
      "MOD-PM-00202    1.183309\n",
      "MOD-PM-00203    1.000295\n",
      "MOD-PM-00205    1.162088\n",
      "MOD-PM-00207    0.933364\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "qaqc_command(batch=\"Batch 3.1\", start=\"2021-05-08 00:00:00\", end=\"2021-05-08 21:00:00\", steady_start='2021-05-08 09:00:00', steady_end='2021-05-08 18:00:00',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff217f2-18d3-4c47-8251-1b32441840ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
